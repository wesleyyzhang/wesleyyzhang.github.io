<!DOCTYPE html>
<html>
  <head>
    <title>CS 180 Proj 5</title>
    <style>
        body {
            font-family: Arial, sans-serif;
            margin: 20px;
        }
        /* Flexbox container for side-by-side images */
        .side-by-side {
            display: flex;
            justify-content: space-between; 
            margin: 20px 0; 
        }
        .side-by-side .image-box {
            text-align: center; 
        }
        .side-by-side img {
            width: 250px; 
            height: auto; 
        }
        .image-box img {
          height: 500px;
          width: auto;
        }
        .make-small img {
          height: 250px;
          width: auto;
        }
        .long {
          display: flex;
        }
        .long_box img {
          width: 5000px;
          height: auto;
        }
        .bballs {
          height: 300px;
          width: auto;
        }
        .bball {
          display: flex;
        }
        .equation-box img {
          width: 800px; 
          height: auto;
        }
    </style>
  </head>
  
  <body>
    <h1>CS 180 Proj 5: Fun with Diffusion Models</h1>

    <h1>Part A: The Power of Diffusion Models!</h1>

    <h2>Part 0: Setup</h2>

    <p>
      First, we use DeepFloyd's IF diffusion model to generate images based on a given prompt. There are 2 stages to this diffusion model.
      The first stage will produce 64x64 sized images and the second stage will upsample the image to output 256x256 sized images. The results 
      of the diffusion model are displayed below. The first set of images were generated with 20 inference steps, and the second set of images were
      generated wth 10 inference steps. 
    
    </p>
    
    <div class="image-box">
      
          <img src="media/generated1.png" alt="Monastery Image">
    </div>

    <div class="image-box">
      
          <img src="media/generated2.png" alt="Monastery Image">
    </div>

    <p>
      The amount of detail appears to go up as the number of inference steps increases. Both sets of images look cartoonish. 
      
    </p>
    

    
    <h2>Part 1: Sampling Loops</h2>

    <p>
      In this part, we iteratively add noise to an image until we get an image of pure noise. We then feed this noisy image into a diffusion model
      which tries to denoise the noisy image. We can either completely remove the noise, or obtain a prediction of the original image. 
    </p>

    
    <h3>1.1 Implementing the Forward Process</h3>

    <p>
      First, we implement the forward process, which takes a clean image and adds noise to it. We do this by following the equation below:
      
    </p>

    <div class="make-small">
           
          <img src="media/Screenshot 2024-11-19 at 5.36.54 PM.png" alt="Monastery Image">
    </div>
    

    <h3>1.2 Classical Denoising</h3>

    <p>
      In this part, we use Gaussiaan blur filtering to try to remove the noise. The results from this will be noticeably worse. 
    </p>

    <h3>1.3 One-Step Denoising</h3>

    <p>
      Lastly, we also use a pretrained diffusion model to denoise the image in a process called one-step denoising. To do this, 
      we will pass in a text prompt since the model was trained with text-conditioning. 
    </p>

    <p>
      I have displayed the results of the previous 3 parts below, with t = [250, 500, 750]. For each column, the top row is the 
      original test image, the second row is the result of the forward steps, the third row is the result of one-step denoising, 
      and the last row is the result of classical denoising. 
    </p>

    <div class="side-by-side">
      <div class="image-box">
           
            <img src="media/1.3_250.png" alt="Monastery Image">
      </div>
      <div class="image-box">
          
            <img src="media/1.3_500.png" alt="Monastery no crop Image">
      </div>
      <div class="image-box">
          
            <img src="media/1.3_750.png" alt="Monastery no crop Image">
      </div>
    </div>
    
  
    <h3>1.4 Iterative Denoising</h3>

    <p>
      In this part, we will implement iterative denoising, which should produce better results than any of the previous parts. 
      To do this, we will follow the below equation:
    </p>

    <div class="make-small">
           
          <img src="media/Screenshot 2024-11-19 at 5.50.14 PM.png" alt="Monastery Image">
    </div>

    <p>
      Each subsequent step of iterative denoising should produce results that are less and less noisy. 
      We will use strided timesteps to prevent us from having to run the model 1000 times. 

      We first create the list of strided timesteps, starting at timestep 990 and taking step sized of 30 until we reach 0. The 
      noisy image after every 5th loop of denoising is displayed. Additionally, the final result of iterative denoising is also
      displayed along with the result of one-step denoising and classical denoising. 
    </p>
    

    <div class="side-by-side">
      <div class="image-box">
           
            <img src="media/1.4_timestamps.png" alt="Monastery Image">
      </div>
      <div class="image-box">
          
            <img src="media/1.4_results.png" alt="Monastery no crop Image">
      </div>
    </div>

    <h3>1.5 Diffusion Model Sampling</h3>

    
    <div class="make-small">
      
          <img src="media/1.5.png" alt="Monastery Image">
    </div>
  
    

    <h3>1.6 Classifier-Free Guidance (CFG)</h3>

    
    <div class="make-small">
      
          <img src="media/1.6.png" alt="Monastery Image">
    </div>
    

    <h3>1.7 Image-to-image Translation</h3>

    <div class="side-by-side">
      <div class="image-box">
           
            <img src="media/1.7.png" alt="Monastery Image">
      </div>
      <div class="image-box">
           
            <img src="media/Screenshot 2024-11-19 at 1.39.30 PM.png" alt="Monastery Image">
      </div>
      <div class="image-box">
           
            <img src="media/Screenshot 2024-11-19 at 1.41.18 PM.png" alt="Monastery Image">
      </div>
    </div>
    

    <h4>1.7.1 Editing Hand-Drawn and Web Images</h4>

    <div class="make-small">
        <img src="media/1.7.1_fruits.png" alt="Monastery Image">
    </div>
    
    <div class="make-small">
        <img src="media/1.7.1_fruits_results.png" alt="Monastery Image">
    </div>
    
    <div class="make-small">
        <img src="media/1.7.1_apple.png" alt="Monastery Image">
    </div>
    
    <div class="make-small">
        <img src="media/1.7.1_apple_results.png" alt="Monastery Image">
    </div>

    <div class="make-small">
        <img src="media/Screenshot 2024-11-19 at 1.43.29 PM.png" alt="Monastery Image">
    </div>
    
    <div class="make-small">
        <img src="media/Screenshot 2024-11-19 at 1.46.09 PM.png" alt="Monastery Image">
    </div>

    <h4>1.7.2 Inpainting</h4>

    <div class="make-small">
        <img src="media/Screenshot 2024-11-19 at 2.11.40 PM.png" alt="Monastery Image">
    </div>
    
    <div class="make-small">
        <img src="media/Screenshot 2024-11-19 at 2.11.54 PM.png" alt="Monastery Image">
    </div>

    <div class="make-small">
        <img src="media/Screenshot 2024-11-19 at 2.12.40 PM.png" alt="Monastery Image">
    </div>
    
    <div class="make-small">
        <img src="media/Screenshot 2024-11-19 at 2.13.24 PM.png" alt="Monastery Image">
    </div>

    <div class="make-small">
        <img src="media/Screenshot 2024-11-19 at 2.12.19 PM.png" alt="Monastery Image">
    </div>
    
    <div class="make-small">
        <img src="media/Screenshot 2024-11-19 at 2.12.56 PM.png" alt="Monastery Image">
    </div>

    

    <h4>1.7.3 Text-Conditional Image-to-image Translation</h4>

    <div class="side-by-side">
      <div class="image-box">
           
            <img src="media/1.7.3.png" alt="Monastery Image">
      </div>

      <div class="image-box">
           
            <img src="media/Screenshot 2024-11-19 at 2.22.21 PM.png" alt="Monastery Image">
      </div>

      <div class="image-box">
           
            <img src="media/Screenshot 2024-11-19 at 2.22.30 PM.png" alt="Monastery Image">
      </div>
    </div>

    

    <h3>1.8 Visual Anagrams</h3>

    <div class="image-box">
         
          <img src="media/1.8.png" alt="Monastery Image">
    </div>

    <div class="image-box">
         
          <img src="media/Screenshot 2024-11-19 at 2.40.01 PM.png" alt="Monastery Image">
    </div>

    <div class="image-box">
         
          <img src="media/Screenshot 2024-11-19 at 2.41.37 PM.png" alt="Monastery Image">
    </div>

    <h3>1.9 Hybrid Images</h3>

    <div class="side-by-side">
      <div class="image-box">
           
            <img src="media/1.10.png" alt="Monastery Image">
      </div>

      <div class="image-box">
           
            <img src="media/Screenshot 2024-11-19 at 2.49.43 PM.png" alt="Monastery Image">
      </div>

      <div class="image-box">
           
            <img src="media/Screenshot 2024-11-19 at 2.55.31 PM.png" alt="Monastery Image">
      </div>
    </div>

    <h1>Part B: Diffusion Models from Scratch!</h1>

    <h2>Part 1: Training a Single-Step Denoising U-Net</h2>

    <h3>1.1 Implementing the UNet</h3>

    <h3>1.2 Using the UNet to Train a Denoiser</h3>

    <div class="make-small">
        <img src="media/5b_part1blur.png" alt="Monastery Image">
    </div>

    <h4>1.2.1 Training</h4>

    <div class="make-small">
        <img src="media/5b_part1traininglosses.png" alt="Monastery Image">
    </div>

    <div class="make-small">
        <img src="media/5b_part1epoch1.png" alt="Monastery Image">
    </div>

    <div class="make-small">
        <img src="media/5b_part1epoch5.png" alt="Monastery Image">
    </div>

    <h4>1.2.2 Out-of-Distribution Testing</h4>

    <div class="make-small">
        <img src="media/5b_part1outofdistribution.png" alt="Monastery Image">
    </div>

    <h2>Part 2: Training a Diffusion Model</h2>

    <h3>2.1 Adding Time Conditioning to UNet</h3>

    <h3>2.2 Training the UNet</h3>

    <div class="make-small">
        <img src="media/5b_part2timeloss.png" alt="Monastery Image">
    </div>

    <h3>2.3 Sampling from the UNet</h3>

    <div class="make-small">
        <img src="media/5b_part2timeepoch5.png" alt="Monastery Image">
    </div>

    <div class="make-small">
        <img src="media/5b_part2timeepoch20.png" alt="Monastery Image">
    </div>

    <h3>2.4 Adding Class-Conditioning to UNet</h3>

    <div class="make-small">
        <img src="media/5b_part2classloss.png" alt="Monastery Image">
    </div>

    <h3>2.5 Sampling from the Class-Conditioned UNet</h3>

    <div class="make-small">
        <img src="media/5b_part2classepoch5.png" alt="Monastery Image">
    </div>

    <div class="make-small">
        <img src="media/5b_part2classepoch20.png" alt="Monastery Image">
    </div>

    
    
  </body>
